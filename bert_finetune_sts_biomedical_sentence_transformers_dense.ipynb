{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "colab": {
      "name": "bert_finetune_sts_biomedical_sentence_transformers_dense.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXgSmDIRAZZh",
        "colab_type": "code",
        "outputId": "4e1fe8aa-89a8-4dc0-9124-932000490ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JufH3ASp0kMJ",
        "colab_type": "code",
        "outputId": "0af099ea-a12b-4000-8841-07c5a310b621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 6.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 43.3MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 48.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.32)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.32)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses, regex\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=d8cf9b41a2a61f53e3718cce79c94b34a155d60455f5abc78e20eaf2c8a2d40a\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609170 sha256=467b0dd265dce41e3701720c2024077468debe3f6a762edae1179f108cb7ac77\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
            "Successfully built sacremoses regex\n",
            "Installing collected packages: sentencepiece, sacremoses, regex, transformers\n",
            "Successfully installed regex-2019.12.9 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y6hfRNET0kMZ",
        "colab_type": "code",
        "outputId": "c1a8beee-c23a-4939-c023-d92630bf79a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/6e/5c98f5f26698276bacd09077b039fa1a00797ed080a628ee844bd9f281d4/sentence-transformers-0.2.4.1.tar.gz (49kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers==2.2.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.2.1->sentence-transformers) (0.0.35)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.2.1->sentence-transformers) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.2.1->sentence-transformers) (2019.12.9)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.2.1->sentence-transformers) (1.10.32)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.2.1->sentence-transformers) (0.1.83)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.2.1->sentence-transformers) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.2.1->sentence-transformers) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.2.1->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.2.1->sentence-transformers) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.2.1->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.2.1->sentence-transformers) (1.13.32)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.2.1->sentence-transformers) (0.2.1)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.2.1->sentence-transformers) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers==2.2.1->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers==2.2.1->sentence-transformers) (2.6.1)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.4.1-cp36-none-any.whl size=61094 sha256=327feef77ce295f15a2e83ae18a1374bc16fa02836c876b40b6e9ff74ea7e5b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/a5/1c/03b7d87e027121fe1e23048007594e73f39a23e833658529c7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-0.2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tgKRiLBw0kMc",
        "colab_type": "code",
        "outputId": "dcfe3169-56be-4868-d5d3-9f332cc86b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "\"\"\"\n",
        "This examples trains BERT for the STSbenchmark from scratch. It generates sentence embeddings\n",
        "that can be compared using cosine-similarity to measure the similarity.\n",
        "\"\"\"\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, models\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.readers import STSDataReader\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "#### Just some code to print debug information to stdout\n",
        "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
        "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "                    level=logging.INFO,\n",
        "                    handlers=[LoggingHandler()])\n",
        "#### /print debug information to stdout"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mqEWk1v90kMh",
        "colab_type": "code",
        "outputId": "7a1e326b-32ed-4e07-efe9-132833e494a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "# Read the dataset\n",
        "train_batch_size = 16\n",
        "num_epochs = 4\n",
        "model_save_path = 'output/training_n2c2_sts_bert-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "# parameters for STSDataReader -> dataset_folder, s1_col_idx=5, s2_col_idx=6, score_col_idx=4, delimiter=\"\\t\", quoting=csv.QUOTE_NONE, normalize_scores=True, min_score=0, max_score=5\n",
        "sts_reader = STSDataReader('', s1_col_idx=0, s2_col_idx=1, score_col_idx=2, normalize_scores=True)\n",
        "\n",
        "# Use BERT for mapping tokens to embeddings\n",
        "word_embedding_model = models.BERT('bert-base-uncased')\n",
        "\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=True,\n",
        "                               pooling_mode_max_tokens=True)\n",
        "\n",
        "#model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "\n",
        "dense1 = models.Dense(in_features=3*word_embedding_model.get_word_embedding_dimension(), out_features=256)\n",
        "dense2 = models.Dense(in_features=256, out_features=64)\n",
        "#dense3 = models.Dense(in_features=64, out_features=8)\n",
        "\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense1, dense2])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 19:49:26 - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpvw87dl2v\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 139394.47B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 19:49:26 - copying /tmp/tmpvw87dl2v to cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
            "2019-12-11 19:49:26 - creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
            "2019-12-11 19:49:26 - removing temp file /tmp/tmpvw87dl2v\n",
            "2019-12-11 19:49:26 - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
            "2019-12-11 19:49:26 - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2019-12-11 19:49:26 - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpnx3hazhg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 440473133/440473133 [00:16<00:00, 26340603.89B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 19:49:43 - copying /tmp/tmpnx3hazhg to cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2019-12-11 19:49:45 - creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2019-12-11 19:49:45 - removing temp file /tmp/tmpnx3hazhg\n",
            "2019-12-11 19:49:45 - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2019-12-11 19:49:48 - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp3lp2lm0x\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 928045.50B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 19:49:48 - copying /tmp/tmp3lp2lm0x to cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2019-12-11 19:49:48 - creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2019-12-11 19:49:48 - removing temp file /tmp/tmp3lp2lm0x\n",
            "2019-12-11 19:49:48 - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2019-12-11 19:49:48 - Use pytorch device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Kn7w48Ya0kMn",
        "colab_type": "code",
        "outputId": "87c55fd1-8126-4c89-eedd-63394159913f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "#sts_reader = STSDataReader('', s1_col_idx=0, s2_col_idx=1, score_col_idx=2, normalize_scores=True)\n",
        "\n",
        "my_drive = '/content/gdrive/My Drive/'\n",
        "\n",
        "# Convert the dataset to a DataLoader ready for training\n",
        "logging.info(\"Read STSbenchmark train dataset\")\n",
        "train_data = SentencesDataset(sts_reader.get_examples(my_drive+'clinicalSTS2019.train_train60.csv'), model)\n",
        "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
        "train_loss = losses.CosineSimilarityLoss(model=model)\n",
        "\n",
        "\n",
        "logging.info(\"Read STSbenchmark dev dataset\")\n",
        "dev_data = SentencesDataset(examples=sts_reader.get_examples(my_drive+'clinicalSTS2019.train_validate20.csv'), model=model)\n",
        "dev_dataloader = DataLoader(dev_data, shuffle=False, batch_size=train_batch_size)\n",
        "evaluator = EmbeddingSimilarityEvaluator(dev_dataloader)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:09 - Read STSbenchmark train dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert dataset: 100%|██████████| 992/992 [00:01<00:00, 978.48it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:10 - Num sentences: 992\n",
            "2019-12-11 20:00:10 - Sentences 0 longer than max_seqence_length: 0\n",
            "2019-12-11 20:00:10 - Sentences 1 longer than max_seqence_length: 0\n",
            "2019-12-11 20:00:10 - Read STSbenchmark dev dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert dataset: 100%|██████████| 331/331 [00:00<00:00, 1021.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:11 - Num sentences: 331\n",
            "2019-12-11 20:00:11 - Sentences 0 longer than max_seqence_length: 0\n",
            "2019-12-11 20:00:11 - Sentences 1 longer than max_seqence_length: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qB69vgWi0kMq",
        "colab_type": "code",
        "outputId": "140b7706-c359-483a-a47d-a9c9abe6fed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Configure the training. We skip evaluation in this example\n",
        "warmup_steps = math.ceil(len(train_data)*num_epochs/train_batch_size*0.1) #10% of train data for warm-up\n",
        "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:11 - Warmup-steps: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eYRlcC2f0kMt",
        "colab_type": "code",
        "outputId": "9d2d186a-2a1c-4210-a8e4-88f2b7e14f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          evaluator=evaluator,\n",
        "          epochs=num_epochs,\n",
        "          evaluation_steps=1000,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=model_save_path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]\n",
            "Iteration:   0%|          | 0/62 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 1/62 [00:00<00:25,  2.40it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 2/62 [00:00<00:23,  2.53it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 3/62 [00:01<00:25,  2.35it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 4/62 [00:01<00:21,  2.68it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 5/62 [00:01<00:22,  2.58it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 6/62 [00:02<00:20,  2.76it/s]\u001b[A\n",
            "Iteration:  11%|█▏        | 7/62 [00:02<00:18,  2.92it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 8/62 [00:02<00:17,  3.00it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 9/62 [00:03<00:18,  2.82it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 10/62 [00:03<00:18,  2.78it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 11/62 [00:03<00:18,  2.80it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 12/62 [00:04<00:17,  2.92it/s]\u001b[A\n",
            "Iteration:  21%|██        | 13/62 [00:04<00:17,  2.82it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 14/62 [00:05<00:17,  2.79it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 15/62 [00:05<00:16,  2.88it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 16/62 [00:05<00:14,  3.17it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 17/62 [00:05<00:14,  3.18it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 18/62 [00:06<00:12,  3.49it/s]\u001b[A\n",
            "Iteration:  31%|███       | 19/62 [00:06<00:15,  2.85it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 20/62 [00:06<00:13,  3.12it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 21/62 [00:07<00:12,  3.29it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 22/62 [00:07<00:12,  3.10it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 23/62 [00:07<00:12,  3.01it/s]\u001b[A\n",
            "Iteration:  39%|███▊      | 24/62 [00:08<00:11,  3.24it/s]\u001b[A\n",
            "Iteration:  40%|████      | 25/62 [00:08<00:10,  3.54it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 26/62 [00:08<00:11,  3.24it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 27/62 [00:09<00:12,  2.73it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 28/62 [00:09<00:12,  2.65it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 29/62 [00:09<00:10,  3.00it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 30/62 [00:10<00:09,  3.36it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 31/62 [00:10<00:08,  3.48it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 32/62 [00:10<00:10,  2.86it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 33/62 [00:11<00:10,  2.81it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 34/62 [00:11<00:09,  3.08it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 35/62 [00:11<00:08,  3.14it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 36/62 [00:12<00:08,  3.22it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 37/62 [00:12<00:07,  3.33it/s]\u001b[A\n",
            "Iteration:  61%|██████▏   | 38/62 [00:12<00:07,  3.13it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 39/62 [00:13<00:07,  3.07it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 40/62 [00:13<00:06,  3.35it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 41/62 [00:13<00:06,  3.37it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 42/62 [00:13<00:06,  3.22it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 43/62 [00:14<00:05,  3.41it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 44/62 [00:14<00:05,  3.50it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 45/62 [00:14<00:05,  3.32it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 46/62 [00:15<00:04,  3.43it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 47/62 [00:15<00:04,  3.09it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 48/62 [00:15<00:04,  2.98it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 49/62 [00:16<00:04,  3.15it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 50/62 [00:16<00:03,  3.11it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 51/62 [00:16<00:03,  2.84it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 52/62 [00:17<00:03,  2.93it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 53/62 [00:17<00:02,  3.06it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 54/62 [00:17<00:02,  3.27it/s]\u001b[A\n",
            "Iteration:  89%|████████▊ | 55/62 [00:18<00:02,  3.05it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 56/62 [00:18<00:01,  3.05it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 57/62 [00:18<00:01,  2.88it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 58/62 [00:19<00:01,  3.14it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 59/62 [00:19<00:00,  3.36it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 60/62 [00:19<00:00,  3.41it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 61/62 [00:19<00:00,  3.55it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 62/62 [00:20<00:00,  3.66it/s]\u001b[A\n",
            "Epoch:   0%|          | 0/4 [00:20<?, ?it/s]\n",
            "Convert Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:31 - Evaluation the model on  dataset after epoch 0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Convert Evaluating:  10%|▉         | 2/21 [00:00<00:01,  9.87it/s]\u001b[A\n",
            "Convert Evaluating:  14%|█▍        | 3/21 [00:00<00:02,  8.94it/s]\u001b[A\n",
            "Convert Evaluating:  24%|██▍       | 5/21 [00:00<00:01,  9.98it/s]\u001b[A\n",
            "Convert Evaluating:  33%|███▎      | 7/21 [00:00<00:01,  9.44it/s]\u001b[A\n",
            "Convert Evaluating:  38%|███▊      | 8/21 [00:00<00:01,  9.44it/s]\u001b[A\n",
            "Convert Evaluating:  48%|████▊     | 10/21 [00:00<00:01, 10.20it/s]\u001b[A\n",
            "Convert Evaluating:  57%|█████▋    | 12/21 [00:01<00:00, 10.83it/s]\u001b[A\n",
            "Convert Evaluating:  67%|██████▋   | 14/21 [00:01<00:00, 10.97it/s]\u001b[A\n",
            "Convert Evaluating:  76%|███████▌  | 16/21 [00:01<00:00, 10.07it/s]\u001b[A\n",
            "Convert Evaluating:  81%|████████  | 17/21 [00:01<00:00,  9.98it/s]\u001b[A\n",
            "Convert Evaluating:  90%|█████████ | 19/21 [00:01<00:00, 10.48it/s]\u001b[A\n",
            "Convert Evaluating: 100%|██████████| 21/21 [00:01<00:00, 12.03it/s]\u001b[A\n",
            "Epoch:   0%|          | 0/4 [00:22<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:33 - Cosine-Similarity :\tPearson: 0.7004\tSpearman: 0.7279\n",
            "2019-12-11 20:00:33 - Manhattan-Distance:\tPearson: 0.7013\tSpearman: 0.7068\n",
            "2019-12-11 20:00:33 - Euclidean-Distance:\tPearson: 0.7065\tSpearman: 0.7098\n",
            "2019-12-11 20:00:33 - Dot-Product-Similarity:\tPearson: 0.5159\tSpearman: 0.5702\n",
            "2019-12-11 20:00:33 - Save model to output/training_n2c2_sts_bert-2019-12-11_19-49-25\n",
            "2019-12-11 20:00:33 - Configuration saved in output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT/config.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  25%|██▌       | 1/4 [00:23<01:09, 23.01s/it]\n",
            "\n",
            "Epoch:  25%|██▌       | 1/4 [00:23<01:09, 23.01s/it]\n",
            "Iteration:   0%|          | 0/62 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:34 - Model weights saved in output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT/pytorch_model.bin\n",
            "2019-12-11 20:00:34 - Restart data_iterator\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration:   2%|▏         | 1/62 [00:00<00:23,  2.64it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 2/62 [00:00<00:21,  2.80it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 3/62 [00:01<00:21,  2.77it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 4/62 [00:01<00:18,  3.07it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 5/62 [00:01<00:21,  2.64it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 6/62 [00:02<00:19,  2.91it/s]\u001b[A\n",
            "Iteration:  11%|█▏        | 7/62 [00:02<00:19,  2.83it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 8/62 [00:02<00:17,  3.01it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 9/62 [00:03<00:18,  2.87it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 10/62 [00:03<00:16,  3.10it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 11/62 [00:03<00:16,  3.03it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 12/62 [00:04<00:16,  2.96it/s]\u001b[A\n",
            "Iteration:  21%|██        | 13/62 [00:04<00:17,  2.85it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 14/62 [00:04<00:17,  2.82it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 15/62 [00:05<00:15,  2.97it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 16/62 [00:05<00:14,  3.10it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 17/62 [00:05<00:13,  3.32it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 18/62 [00:06<00:14,  3.13it/s]\u001b[A\n",
            "Iteration:  31%|███       | 19/62 [00:06<00:13,  3.15it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 20/62 [00:06<00:12,  3.30it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 21/62 [00:06<00:13,  3.13it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 22/62 [00:07<00:12,  3.15it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 23/62 [00:07<00:14,  2.70it/s]\u001b[A\n",
            "Iteration:  39%|███▊      | 24/62 [00:08<00:14,  2.65it/s]\u001b[A\n",
            "Iteration:  40%|████      | 25/62 [00:08<00:12,  2.92it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 26/62 [00:08<00:11,  3.12it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 27/62 [00:08<00:11,  3.16it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 28/62 [00:09<00:10,  3.39it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 29/62 [00:09<00:10,  3.15it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 30/62 [00:09<00:10,  2.99it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 31/62 [00:10<00:09,  3.10it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 32/62 [00:10<00:10,  2.79it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 33/62 [00:11<00:10,  2.75it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 34/62 [00:11<00:08,  3.12it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 35/62 [00:11<00:08,  3.27it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 36/62 [00:12<00:08,  2.94it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 37/62 [00:12<00:07,  3.14it/s]\u001b[A\n",
            "Iteration:  61%|██████▏   | 38/62 [00:12<00:07,  3.24it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 39/62 [00:12<00:07,  3.06it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 40/62 [00:13<00:07,  2.81it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 41/62 [00:13<00:07,  2.96it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 42/62 [00:13<00:06,  3.22it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 43/62 [00:14<00:05,  3.22it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 44/62 [00:14<00:05,  3.08it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 45/62 [00:14<00:05,  3.21it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 46/62 [00:15<00:05,  3.07it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 47/62 [00:15<00:05,  2.97it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 48/62 [00:15<00:04,  3.04it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 49/62 [00:16<00:04,  3.11it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 50/62 [00:16<00:04,  2.66it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 51/62 [00:17<00:04,  2.60it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 52/62 [00:17<00:03,  2.55it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 53/62 [00:17<00:03,  2.89it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 54/62 [00:18<00:02,  2.78it/s]\u001b[A\n",
            "Iteration:  89%|████████▊ | 55/62 [00:18<00:02,  3.06it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 56/62 [00:18<00:01,  3.39it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 57/62 [00:18<00:01,  3.57it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 58/62 [00:19<00:01,  3.46it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 59/62 [00:19<00:00,  3.01it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 60/62 [00:19<00:00,  3.15it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 61/62 [00:20<00:00,  3.04it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 62/62 [00:20<00:00,  2.87it/s]\u001b[A\n",
            "Epoch:  25%|██▌       | 1/4 [00:43<01:09, 23.01s/it]\n",
            "Convert Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:55 - Evaluation the model on  dataset after epoch 1:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Convert Evaluating:  10%|▉         | 2/21 [00:00<00:01,  9.64it/s]\u001b[A\n",
            "Convert Evaluating:  14%|█▍        | 3/21 [00:00<00:02,  8.78it/s]\u001b[A\n",
            "Convert Evaluating:  24%|██▍       | 5/21 [00:00<00:01,  9.82it/s]\u001b[A\n",
            "Convert Evaluating:  33%|███▎      | 7/21 [00:00<00:01,  9.27it/s]\u001b[A\n",
            "Convert Evaluating:  38%|███▊      | 8/21 [00:00<00:01,  9.31it/s]\u001b[A\n",
            "Convert Evaluating:  48%|████▊     | 10/21 [00:01<00:01, 10.11it/s]\u001b[A\n",
            "Convert Evaluating:  57%|█████▋    | 12/21 [00:01<00:00, 10.71it/s]\u001b[A\n",
            "Convert Evaluating:  67%|██████▋   | 14/21 [00:01<00:00, 10.91it/s]\u001b[A\n",
            "Convert Evaluating:  76%|███████▌  | 16/21 [00:01<00:00, 10.05it/s]\u001b[A\n",
            "Convert Evaluating:  81%|████████  | 17/21 [00:01<00:00,  9.99it/s]\u001b[A\n",
            "Convert Evaluating:  90%|█████████ | 19/21 [00:01<00:00, 10.48it/s]\u001b[A\n",
            "Convert Evaluating: 100%|██████████| 21/21 [00:01<00:00, 11.98it/s]\u001b[A\n",
            "Epoch:  50%|█████     | 2/4 [00:45<00:45, 22.90s/it]\n",
            "\n",
            "Epoch:  50%|█████     | 2/4 [00:45<00:45, 22.90s/it]\n",
            "Iteration:   0%|          | 0/62 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:00:57 - Cosine-Similarity :\tPearson: 0.6905\tSpearman: 0.6969\n",
            "2019-12-11 20:00:57 - Manhattan-Distance:\tPearson: 0.6733\tSpearman: 0.6620\n",
            "2019-12-11 20:00:57 - Euclidean-Distance:\tPearson: 0.6806\tSpearman: 0.6690\n",
            "2019-12-11 20:00:57 - Dot-Product-Similarity:\tPearson: 0.5122\tSpearman: 0.5383\n",
            "2019-12-11 20:00:57 - Restart data_iterator\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration:   2%|▏         | 1/62 [00:00<00:25,  2.36it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 2/62 [00:00<00:25,  2.35it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 3/62 [00:01<00:23,  2.55it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 4/62 [00:01<00:20,  2.82it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 5/62 [00:01<00:19,  2.93it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 6/62 [00:01<00:17,  3.17it/s]\u001b[A\n",
            "Iteration:  11%|█▏        | 7/62 [00:02<00:17,  3.10it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 8/62 [00:02<00:16,  3.28it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 9/62 [00:02<00:16,  3.29it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 10/62 [00:03<00:16,  3.17it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 11/62 [00:03<00:14,  3.42it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 12/62 [00:03<00:17,  2.82it/s]\u001b[A\n",
            "Iteration:  21%|██        | 13/62 [00:04<00:15,  3.22it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 14/62 [00:04<00:16,  2.92it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 15/62 [00:04<00:16,  2.87it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 16/62 [00:05<00:14,  3.17it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 17/62 [00:05<00:15,  2.93it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 18/62 [00:05<00:14,  2.99it/s]\u001b[A\n",
            "Iteration:  31%|███       | 19/62 [00:06<00:14,  2.97it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 20/62 [00:06<00:13,  3.19it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 21/62 [00:06<00:12,  3.40it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 22/62 [00:07<00:11,  3.52it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 23/62 [00:07<00:11,  3.52it/s]\u001b[A\n",
            "Iteration:  39%|███▊      | 24/62 [00:07<00:11,  3.45it/s]\u001b[A\n",
            "Iteration:  40%|████      | 25/62 [00:07<00:11,  3.26it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 26/62 [00:08<00:11,  3.27it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 27/62 [00:08<00:11,  3.02it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 28/62 [00:08<00:10,  3.29it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 29/62 [00:09<00:09,  3.40it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 30/62 [00:09<00:09,  3.32it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 31/62 [00:09<00:09,  3.28it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 32/62 [00:10<00:09,  3.27it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 33/62 [00:10<00:09,  3.08it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 34/62 [00:10<00:09,  2.82it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 35/62 [00:11<00:10,  2.69it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 36/62 [00:11<00:10,  2.53it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 37/62 [00:12<00:09,  2.72it/s]\u001b[A\n",
            "Iteration:  61%|██████▏   | 38/62 [00:12<00:08,  2.90it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 39/62 [00:12<00:08,  2.82it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 40/62 [00:13<00:07,  3.06it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 41/62 [00:13<00:06,  3.33it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 42/62 [00:13<00:05,  3.43it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 43/62 [00:13<00:05,  3.59it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 44/62 [00:13<00:04,  3.81it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 45/62 [00:14<00:05,  2.99it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 46/62 [00:14<00:05,  2.70it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 47/62 [00:15<00:05,  2.96it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 48/62 [00:15<00:04,  3.09it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 49/62 [00:15<00:03,  3.32it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 50/62 [00:15<00:03,  3.51it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 51/62 [00:16<00:03,  3.27it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 52/62 [00:16<00:02,  3.40it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 53/62 [00:16<00:02,  3.60it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 54/62 [00:17<00:02,  3.56it/s]\u001b[A\n",
            "Iteration:  89%|████████▊ | 55/62 [00:17<00:02,  3.36it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 56/62 [00:17<00:01,  3.12it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 57/62 [00:18<00:01,  3.22it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 58/62 [00:18<00:01,  3.45it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 59/62 [00:18<00:00,  3.37it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 60/62 [00:19<00:00,  2.79it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 61/62 [00:19<00:00,  2.79it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 62/62 [00:19<00:00,  3.05it/s]\u001b[A\n",
            "Epoch:  50%|█████     | 2/4 [01:05<00:45, 22.90s/it]\n",
            "Convert Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:01:16 - Evaluation the model on  dataset after epoch 2:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Convert Evaluating:  10%|▉         | 2/21 [00:00<00:01,  9.67it/s]\u001b[A\n",
            "Convert Evaluating:  14%|█▍        | 3/21 [00:00<00:02,  8.79it/s]\u001b[A\n",
            "Convert Evaluating:  24%|██▍       | 5/21 [00:00<00:01,  9.85it/s]\u001b[A\n",
            "Convert Evaluating:  33%|███▎      | 7/21 [00:00<00:01,  9.36it/s]\u001b[A\n",
            "Convert Evaluating:  38%|███▊      | 8/21 [00:00<00:01,  9.37it/s]\u001b[A\n",
            "Convert Evaluating:  48%|████▊     | 10/21 [00:00<00:01, 10.16it/s]\u001b[A\n",
            "Convert Evaluating:  57%|█████▋    | 12/21 [00:01<00:00, 10.81it/s]\u001b[A\n",
            "Convert Evaluating:  67%|██████▋   | 14/21 [00:01<00:00, 10.96it/s]\u001b[A\n",
            "Convert Evaluating:  76%|███████▌  | 16/21 [00:01<00:00, 10.05it/s]\u001b[A\n",
            "Convert Evaluating:  86%|████████▌ | 18/21 [00:01<00:00, 10.52it/s]\u001b[A\n",
            "Convert Evaluating:  95%|█████████▌| 20/21 [00:01<00:00, 11.08it/s]\u001b[A\n",
            "Epoch:  75%|███████▌  | 3/4 [01:07<00:22, 22.58s/it]\n",
            "\n",
            "Epoch:  75%|███████▌  | 3/4 [01:07<00:22, 22.58s/it]\n",
            "Iteration:   0%|          | 0/62 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:01:18 - Cosine-Similarity :\tPearson: 0.6836\tSpearman: 0.6832\n",
            "2019-12-11 20:01:18 - Manhattan-Distance:\tPearson: 0.6172\tSpearman: 0.6054\n",
            "2019-12-11 20:01:18 - Euclidean-Distance:\tPearson: 0.6174\tSpearman: 0.6021\n",
            "2019-12-11 20:01:18 - Dot-Product-Similarity:\tPearson: 0.5488\tSpearman: 0.5987\n",
            "2019-12-11 20:01:18 - Restart data_iterator\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration:   2%|▏         | 1/62 [00:00<00:20,  2.93it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 2/62 [00:00<00:18,  3.17it/s]\u001b[A\n",
            "Iteration:   5%|▍         | 3/62 [00:00<00:17,  3.33it/s]\u001b[A\n",
            "Iteration:   6%|▋         | 4/62 [00:01<00:16,  3.42it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 5/62 [00:01<00:16,  3.51it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 6/62 [00:01<00:17,  3.17it/s]\u001b[A\n",
            "Iteration:  11%|█▏        | 7/62 [00:02<00:18,  3.05it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 8/62 [00:02<00:19,  2.77it/s]\u001b[A\n",
            "Iteration:  15%|█▍        | 9/62 [00:02<00:18,  2.83it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 10/62 [00:03<00:16,  3.17it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 11/62 [00:03<00:16,  3.01it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 12/62 [00:03<00:16,  2.96it/s]\u001b[A\n",
            "Iteration:  21%|██        | 13/62 [00:04<00:15,  3.07it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 14/62 [00:04<00:14,  3.25it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 15/62 [00:04<00:14,  3.25it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 16/62 [00:05<00:16,  2.74it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 17/62 [00:05<00:16,  2.76it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 18/62 [00:05<00:16,  2.71it/s]\u001b[A\n",
            "Iteration:  31%|███       | 19/62 [00:06<00:15,  2.69it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 20/62 [00:06<00:13,  3.03it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 21/62 [00:06<00:14,  2.85it/s]\u001b[A\n",
            "Iteration:  35%|███▌      | 22/62 [00:07<00:12,  3.11it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 23/62 [00:07<00:12,  3.04it/s]\u001b[A\n",
            "Iteration:  39%|███▊      | 24/62 [00:07<00:12,  3.02it/s]\u001b[A\n",
            "Iteration:  40%|████      | 25/62 [00:08<00:13,  2.84it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 26/62 [00:08<00:12,  2.83it/s]\u001b[A\n",
            "Iteration:  44%|████▎     | 27/62 [00:08<00:11,  3.11it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 28/62 [00:09<00:11,  3.01it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 29/62 [00:09<00:10,  3.19it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 30/62 [00:09<00:10,  3.09it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 31/62 [00:10<00:09,  3.17it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 32/62 [00:10<00:09,  3.32it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 33/62 [00:10<00:08,  3.22it/s]\u001b[A\n",
            "Iteration:  55%|█████▍    | 34/62 [00:11<00:08,  3.42it/s]\u001b[A\n",
            "Iteration:  56%|█████▋    | 35/62 [00:11<00:08,  3.26it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 36/62 [00:11<00:08,  3.17it/s]\u001b[A\n",
            "Iteration:  60%|█████▉    | 37/62 [00:11<00:07,  3.51it/s]\u001b[A\n",
            "Iteration:  61%|██████▏   | 38/62 [00:12<00:07,  3.43it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 39/62 [00:12<00:06,  3.67it/s]\u001b[A\n",
            "Iteration:  65%|██████▍   | 40/62 [00:12<00:07,  2.94it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 41/62 [00:13<00:06,  3.21it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 42/62 [00:13<00:06,  3.29it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 43/62 [00:13<00:05,  3.34it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 44/62 [00:14<00:05,  3.39it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 45/62 [00:14<00:05,  3.32it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 46/62 [00:14<00:05,  2.77it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 47/62 [00:15<00:05,  2.95it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 48/62 [00:15<00:04,  2.87it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 49/62 [00:15<00:03,  3.26it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 50/62 [00:16<00:03,  3.27it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 51/62 [00:16<00:03,  3.32it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 52/62 [00:16<00:02,  3.63it/s]\u001b[A\n",
            "Iteration:  85%|████████▌ | 53/62 [00:16<00:02,  3.38it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 54/62 [00:17<00:02,  3.03it/s]\u001b[A\n",
            "Iteration:  89%|████████▊ | 55/62 [00:17<00:02,  3.36it/s]\u001b[A\n",
            "Iteration:  90%|█████████ | 56/62 [00:17<00:01,  3.00it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 57/62 [00:18<00:01,  2.97it/s]\u001b[A\n",
            "Iteration:  94%|█████████▎| 58/62 [00:18<00:01,  2.78it/s]\u001b[A\n",
            "Iteration:  95%|█████████▌| 59/62 [00:19<00:01,  2.58it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 60/62 [00:19<00:00,  2.51it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 61/62 [00:19<00:00,  2.77it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 62/62 [00:20<00:00,  2.95it/s]\u001b[A\n",
            "Epoch:  75%|███████▌  | 3/4 [01:27<00:22, 22.58s/it]\n",
            "Convert Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:01:39 - Evaluation the model on  dataset after epoch 3:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Convert Evaluating:  10%|▉         | 2/21 [00:00<00:01,  9.67it/s]\u001b[A\n",
            "Convert Evaluating:  14%|█▍        | 3/21 [00:00<00:02,  8.71it/s]\u001b[A\n",
            "Convert Evaluating:  24%|██▍       | 5/21 [00:00<00:01,  9.78it/s]\u001b[A\n",
            "Convert Evaluating:  33%|███▎      | 7/21 [00:00<00:01,  9.27it/s]\u001b[A\n",
            "Convert Evaluating:  38%|███▊      | 8/21 [00:00<00:01,  9.26it/s]\u001b[A\n",
            "Convert Evaluating:  48%|████▊     | 10/21 [00:01<00:01, 10.05it/s]\u001b[A\n",
            "Convert Evaluating:  57%|█████▋    | 12/21 [00:01<00:00, 10.73it/s]\u001b[A\n",
            "Convert Evaluating:  67%|██████▋   | 14/21 [00:01<00:00, 10.91it/s]\u001b[A\n",
            "Convert Evaluating:  76%|███████▌  | 16/21 [00:01<00:00, 10.05it/s]\u001b[A\n",
            "Convert Evaluating:  81%|████████  | 17/21 [00:01<00:00, 10.00it/s]\u001b[A\n",
            "Convert Evaluating:  90%|█████████ | 19/21 [00:01<00:00, 10.48it/s]\u001b[A\n",
            "Convert Evaluating: 100%|██████████| 21/21 [00:01<00:00, 12.02it/s]\u001b[A\n",
            "Epoch: 100%|██████████| 4/4 [01:29<00:00, 22.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:01:41 - Cosine-Similarity :\tPearson: 0.7152\tSpearman: 0.7195\n",
            "2019-12-11 20:01:41 - Manhattan-Distance:\tPearson: 0.6525\tSpearman: 0.6459\n",
            "2019-12-11 20:01:41 - Euclidean-Distance:\tPearson: 0.6573\tSpearman: 0.6448\n",
            "2019-12-11 20:01:41 - Dot-Product-Similarity:\tPearson: 0.5986\tSpearman: 0.6413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7DzTfukm0kMw",
        "colab_type": "code",
        "outputId": "b29f0530-448d-4915-9d1d-4d193b4fb1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "##############################################################################\n",
        "#\n",
        "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
        "#\n",
        "##############################################################################\n",
        "\n",
        "model = SentenceTransformer(model_save_path)\n",
        "test_data = SentencesDataset(examples=sts_reader.get_examples(my_drive+\"clinicalSTS2019.train_test20.csv\"), model=model)\n",
        "test_dataloader = DataLoader(test_data, shuffle=False, batch_size=train_batch_size)\n",
        "evaluator = EmbeddingSimilarityEvaluator(test_dataloader)\n",
        "model.evaluate(evaluator)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:09:36 - Load pretrained SentenceTransformer: output/training_n2c2_sts_bert-2019-12-11_19-49-25\n",
            "2019-12-11 20:09:36 - Load SentenceTransformer from folder: output/training_n2c2_sts_bert-2019-12-11_19-49-25\n",
            "2019-12-11 20:09:36 - loading configuration file output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT/config.json\n",
            "2019-12-11 20:09:36 - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2019-12-11 20:09:36 - loading weights file output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT/pytorch_model.bin\n",
            "2019-12-11 20:09:38 - Model name 'output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT' is a path or url to a directory containing tokenizer files.\n",
            "2019-12-11 20:09:38 - loading file output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT/vocab.txt\n",
            "2019-12-11 20:09:38 - loading file output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT/added_tokens.json\n",
            "2019-12-11 20:09:38 - loading file output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT/special_tokens_map.json\n",
            "2019-12-11 20:09:38 - loading file output/training_n2c2_sts_bert-2019-12-11_19-49-25/0_BERT/tokenizer_config.json\n",
            "2019-12-11 20:09:39 - Use pytorch device: cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert dataset: 100%|██████████| 331/331 [00:00<00:00, 1039.76it/s]\n",
            "Convert Evaluating:  10%|▉         | 2/21 [00:00<00:01, 10.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:09:39 - Num sentences: 331\n",
            "2019-12-11 20:09:39 - Sentences 0 longer than max_seqence_length: 0\n",
            "2019-12-11 20:09:39 - Sentences 1 longer than max_seqence_length: 0\n",
            "2019-12-11 20:09:39 - Evaluation the model on  dataset:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 21/21 [00:01<00:00, 12.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-11 20:09:41 - Cosine-Similarity :\tPearson: 0.6864\tSpearman: 0.6851\n",
            "2019-12-11 20:09:41 - Manhattan-Distance:\tPearson: 0.6813\tSpearman: 0.6606\n",
            "2019-12-11 20:09:41 - Euclidean-Distance:\tPearson: 0.6854\tSpearman: 0.6662\n",
            "2019-12-11 20:09:41 - Dot-Product-Similarity:\tPearson: 0.5486\tSpearman: 0.5511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6851091758294848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsee_LAZATg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r output.zip output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMTz9vGGAdJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp output.zip '/content/gdrive/My Drive/bert_finetuned_sts_biomedical_dense.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}